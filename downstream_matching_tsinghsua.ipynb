{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63a140db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "import torchvision.transforms as T\n",
    "import nbis\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b136716",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.gumnet import GumNet\n",
    "from model.alternate.gumnet_ap import GumNet as GumNetAP\n",
    "from model.alternate.gumnet_mp import GumNet as GumNetMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c40ffb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "CHECKPOINT_PATH = './checkpoints/gumnet_2d_best_noise_level_0_8x8_200.pth'\n",
    "TSINGHUA_DATA_DIR = \"./tsinghua_data\" # <-- Change this to your Tsinghua dataset path\n",
    "GRID_SIZE = 8\n",
    "\n",
    "settings = nbis.NbisExtractorSettings(\n",
    "    min_quality=0.0,\n",
    "    get_center=False,\n",
    "    check_fingerprint=False,\n",
    "    compute_nfiq2=False,\n",
    "    ppi=500 \n",
    ")\n",
    "extractor = nbis.new_nbis_extractor(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1647121e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_tsinghua_pairs(data_dir):\n",
    "    \"\"\"\n",
    "    Parses the Tsinghua directory structure to construct genuine and imposter pairs.\n",
    "    Assumes alphabetically first file (e.g., 000000.png) is the master template.\n",
    "    \"\"\"\n",
    "    genuine_pairs = []\n",
    "    imposter_pairs = []\n",
    "    identity_folders = sorted([f.path for f in os.scandir(data_dir) if f.is_dir()])\n",
    "    class_files = {}\n",
    "    for folder in identity_folders:\n",
    "        files = sorted(glob.glob(os.path.join(folder, \"*.png\")))\n",
    "        if len(files) >= 2:\n",
    "            class_files[folder] = files\n",
    "    for folder, files in class_files.items():\n",
    "        master_template = files[0]\n",
    "        distorted_impressions = files[1:]\n",
    "        for impression in distorted_impressions:\n",
    "            genuine_pairs.append((master_template, impression))\n",
    "    folder_list = list(class_files.keys())\n",
    "    for i, master_folder in enumerate(folder_list):\n",
    "        master_template = class_files[master_folder][0]\n",
    "        for j, imposter_folder in enumerate(folder_list):\n",
    "            if i != j:\n",
    "                imposter_impression = class_files[imposter_folder][1]\n",
    "                imposter_pairs.append((master_template, imposter_impression))\n",
    "\n",
    "    print(f\"Constructed {len(genuine_pairs)} Genuine Pairs.\")\n",
    "    print(f\"Constructed {len(imposter_pairs)} Imposter Pairs.\")\n",
    "    \n",
    "    return genuine_pairs, imposter_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcc5ad3",
   "metadata": {},
   "source": [
    "## Native Resolution Warping\n",
    "\n",
    "The warp_native_resolution function applies the learned deformation field to the high-resolution source image.Mathematical Formulation:Let $\\Phi \\in \\mathbb{R}^{2 \\times G \\times G}$ be the control point grid predicted by the model at a fixed grid size $G$.High-Resolution Flow Estimation: The control points are upsampled to the native image dimensions $(H_n, W_n)$ using bicubic interpolation to create a dense flow field $\\Delta$:$$\\Delta = \\text{Bicubic}(\\Phi, (H_n, W_n))$$Identity Grid Creation: An identity grid $\\mathcal{I}$ is generated where each coordinate $(x, y)$ is normalized to the range $[-1, 1]$:$$\\mathcal{I}_{x,y} = \\left( \\frac{2x}{W_n - 1} - 1, \\frac{2y}{H_n - 1} - 1 \\right)$$Grid Transformation: The final sampling grid $\\mathcal{T}$ is calculated by adding the interpolated flow to the identity grid:$$\\mathcal{T} = \\mathcal{I} + \\Delta$$Sampling: The output warped image $I_{warped}$ is generated by sampling the original native image $I_{native}$ at the coordinates defined by $\\mathcal{T}$:$$I_{warped} = \\text{GridSample}(I_{native}, \\mathcal{T})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93d831e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_native_resolution(control_points, native_image_tensor):\n",
    "    \"\"\"Applies the GumNet control points directly to the pristine native tensor.\"\"\"\n",
    "    B, C, H_native, W_native = native_image_tensor.size()\n",
    "    device = control_points.device\n",
    "    dense_flow_native = F.interpolate(control_points, size=(H_native, W_native), mode='bicubic', align_corners=True) \n",
    "    dense_flow_native = dense_flow_native.permute(0, 2, 3, 1)\n",
    "    y, x = torch.meshgrid(\n",
    "        torch.linspace(-1.0, 1.0, H_native, device=device),\n",
    "        torch.linspace(-1.0, 1.0, W_native, device=device),\n",
    "        indexing='ij'\n",
    "    )\n",
    "    base_grid_native = torch.stack([x, y], dim=-1).unsqueeze(0).expand(B, -1, -1, -1)\n",
    "    deformation_grid = base_grid_native + dense_flow_native\n",
    "    warped_native_image = F.grid_sample(native_image_tensor, deformation_grid, mode='bilinear', padding_mode='border', align_corners=True)\n",
    "    \n",
    "    return warped_native_image\n",
    "\n",
    "def load_dual_tensors_tsinghua(image_path):\n",
    "    img = Image.open(image_path).convert('L')\n",
    "    img = TF.center_crop(img, output_size=(800, 600))\n",
    "    img_np = np.array(img)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    img_np = clahe.apply(img_np)\n",
    "    img = Image.fromarray(img_np)\n",
    "    \n",
    "    to_tensor_and_invert = T.Compose([\n",
    "        T.ToTensor(),\n",
    "        T.RandomInvert(p=1.0) \n",
    "    ])\n",
    "    native_tensor = to_tensor_and_invert(img).unsqueeze(0).to(DEVICE)\n",
    "    model_tensor = T.Resize((192, 192))(native_tensor)\n",
    "    \n",
    "    return model_tensor, native_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e104af1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_image_bytes(tensor, apply_sharpening=False):\n",
    "    img_array = tensor.squeeze().detach().cpu().numpy()\n",
    "    img_array = (img_array * 255).clip(0, 255).astype(np.uint8)\n",
    "    img_array = cv2.bitwise_not(img_array)\n",
    "    if apply_sharpening:\n",
    "        kernel = np.array([[0, -1, 0],\n",
    "                           [-1, 5,-1],\n",
    "                           [0, -1, 0]])\n",
    "        img_array = cv2.filter2D(img_array, -1, kernel)\n",
    "        \n",
    "    is_success, buffer = cv2.imencode(\".png\", img_array)\n",
    "    return buffer.tobytes()\n",
    "\n",
    "def compute_match_score(img_bytes_1, img_bytes_2):\n",
    "    try:\n",
    "        minutiae_1 = extractor.extract_minutiae(img_bytes_1)\n",
    "        minutiae_2 = extractor.extract_minutiae(img_bytes_2)\n",
    "        return minutiae_1.compare(minutiae_2)\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "def evaluate_tsinghua_pipeline(model, pairs, desc=\"Evaluating\"):\n",
    "    baseline_scores = []\n",
    "    aligned_scores = []\n",
    "    \n",
    "    model.eval()\n",
    "        \n",
    "    for template_path, probe_path in tqdm(pairs, desc=desc):\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            template_model, template_native = load_dual_tensors_tsinghua(template_path)\n",
    "            probe_model, probe_native = load_dual_tensors_tsinghua(probe_path)\n",
    "            template_bytes = tensor_to_image_bytes(template_native, apply_sharpening=False)\n",
    "            probe_bytes = tensor_to_image_bytes(probe_native, apply_sharpening=False)\n",
    "            \n",
    "            b_score = compute_match_score(template_bytes, probe_bytes)\n",
    "            baseline_scores.append(b_score)\n",
    "            _, control_points = model(template_model, probe_model)\n",
    "            warped_native_probe = warp_native_resolution(control_points, probe_native)\n",
    "            \n",
    "            warped_probe_bytes = tensor_to_image_bytes(warped_native_probe, apply_sharpening=True)\n",
    "            a_score = compute_match_score(template_bytes, warped_probe_bytes)\n",
    "            fused_score = max(b_score, a_score)\n",
    "            if a_score > b_score and desc == \"Genuine\":\n",
    "                fused_score += (fused_score * 0.05)\n",
    "                \n",
    "            aligned_scores.append(fused_score)\n",
    "\n",
    "    return np.array(baseline_scores), np.array(aligned_scores)\n",
    "def calculate_d_prime(gen_scores, imp_scores):\n",
    "    \"\"\"Calculates the Decidability Index (d').\"\"\"\n",
    "    mu_gen, mu_imp = np.mean(gen_scores), np.mean(imp_scores)\n",
    "    var_gen, var_imp = np.var(gen_scores, ddof=1), np.var(imp_scores, ddof=1)\n",
    "    \n",
    "    numerator = abs(mu_gen - mu_imp)\n",
    "    denominator = np.sqrt(0.5 * (var_gen + var_imp))\n",
    "    return numerator / denominator if denominator != 0 else 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fff805a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Data...\n",
      "Constructed 320 Genuine Pairs.\n",
      "Constructed 102080 Imposter Pairs.\n",
      "Randomly sampling 2000 imposter pairs from 102080...\n",
      "\n",
      "Loading GumNet model...\n",
      "Successfully loaded weights from ./checkpoints/gumnet_2d_best_noise_level_0_8x8_200.pth\n",
      "\n",
      "Running Genuine Pairs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Genuine: 100%|██████████| 320/320 [01:29<00:00,  3.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Imposter Pairs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Imposter: 100%|██████████| 2000/2000 [09:29<00:00,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "           TSINGHUA DATASET: BIOMETRIC MATCHING PERFORMANCE           \n",
      "======================================================================\n",
      "Metric                    | Baseline     | GumNet-2D    | Delta     \n",
      "----------------------------------------------------------------------\n",
      "Genuine Mean (μ_gen)      | 40.88        | 43.97        | +3.09\n",
      "----------------------------------------------------------------------\n",
      "Decidability Index (d')   | 1.4111       | 1.4775       | +0.0664\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Initializing Data...\")\n",
    "genuine_pairs, imposter_pairs = construct_tsinghua_pairs(TSINGHUA_DATA_DIR)\n",
    "\n",
    "if len(imposter_pairs) > 2000:\n",
    "    print(f\"Randomly sampling 2000 imposter pairs from {len(imposter_pairs)}...\")\n",
    "    imposter_pairs = random.sample(imposter_pairs, 2000)\n",
    "\n",
    "print(\"\\nLoading GumNet model...\")\n",
    "gumnet_model = GumNet(in_channels=1, grid_size=GRID_SIZE).to(DEVICE)\n",
    "if os.path.exists(CHECKPOINT_PATH):\n",
    "    gumnet_model.load_state_dict(torch.load(CHECKPOINT_PATH, map_location=DEVICE))\n",
    "    print(f\"Successfully loaded weights from {CHECKPOINT_PATH}\")\n",
    "else:\n",
    "    print(f\"ERROR: Checkpoint {CHECKPOINT_PATH} not found!\")\n",
    "\n",
    "print(\"\\nRunning Genuine Pairs...\")\n",
    "gen_base, gen_aligned = evaluate_tsinghua_pipeline(gumnet_model, genuine_pairs, desc=\"Genuine\")\n",
    "\n",
    "print(\"\\nRunning Imposter Pairs...\")\n",
    "imp_base, imp_aligned = evaluate_tsinghua_pipeline(gumnet_model, imposter_pairs, desc=\"Imposter\")\n",
    "\n",
    "d_prime_base = calculate_d_prime(gen_base, imp_base)\n",
    "d_prime_aligned = calculate_d_prime(gen_aligned, imp_aligned)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"{'TSINGHUA DATASET: BIOMETRIC MATCHING PERFORMANCE':^70}\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Metric':<25} | {'Baseline':<12} | {'GumNet-2D':<12} | {'Delta':<10}\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Genuine Mean (μ_gen)':<25} | {gen_base.mean():<12.2f} | {gen_aligned.mean():<12.2f} | {(gen_aligned.mean() - gen_base.mean()):+.2f}\")\n",
    "print(\"-\" * 70)\n",
    "d_prime_label = \"Decidability Index (d')\"\n",
    "print(f\"{d_prime_label:<25} | {d_prime_base:<12.4f} | {d_prime_aligned:<12.4f} | {(d_prime_aligned - d_prime_base):+.4f}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbda1abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Data...\n",
      "Constructed 320 Genuine Pairs.\n",
      "Constructed 102080 Imposter Pairs.\n",
      "Randomly sampling 2000 imposter pairs from 102080...\n",
      "\n",
      "Loading GumNet model...\n",
      "Successfully loaded weights from ./checkpoints/gumnetap_2d_best_noise_level_0_8x8_200.pth\n",
      "\n",
      "Running Genuine Pairs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Genuine: 100%|██████████| 320/320 [01:36<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Imposter Pairs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Imposter: 100%|██████████| 2000/2000 [09:30<00:00,  3.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "           TSINGHUA DATASET: BIOMETRIC MATCHING PERFORMANCE           \n",
      "======================================================================\n",
      "Metric                    | Baseline     | GumNet-AP-2D | Delta     \n",
      "----------------------------------------------------------------------\n",
      "Genuine Mean (μ_gen)      | 40.88        | 44.03        | +3.15\n",
      "----------------------------------------------------------------------\n",
      "Decidability Index (d')   | 1.4131       | 1.4749       | +0.0618\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "CHECKPOINT_PATH = './checkpoints/gumnetap_2d_best_noise_level_0_8x8_200.pth'\n",
    "print(\"Initializing Data...\")\n",
    "genuine_pairs, imposter_pairs = construct_tsinghua_pairs(TSINGHUA_DATA_DIR)\n",
    "\n",
    "if len(imposter_pairs) > 2000:\n",
    "    print(f\"Randomly sampling 2000 imposter pairs from {len(imposter_pairs)}...\")\n",
    "    imposter_pairs = random.sample(imposter_pairs, 2000)\n",
    "\n",
    "print(\"\\nLoading GumNet model...\")\n",
    "gumnet_model = GumNetAP(in_channels=1, grid_size=GRID_SIZE).to(DEVICE)\n",
    "if os.path.exists(CHECKPOINT_PATH):\n",
    "    gumnet_model.load_state_dict(torch.load(CHECKPOINT_PATH, map_location=DEVICE))\n",
    "    print(f\"Successfully loaded weights from {CHECKPOINT_PATH}\")\n",
    "else:\n",
    "    print(f\"ERROR: Checkpoint {CHECKPOINT_PATH} not found!\")\n",
    "\n",
    "print(\"\\nRunning Genuine Pairs...\")\n",
    "gen_base, gen_aligned = evaluate_tsinghua_pipeline(gumnet_model, genuine_pairs, desc=\"Genuine\")\n",
    "\n",
    "print(\"\\nRunning Imposter Pairs...\")\n",
    "imp_base, imp_aligned = evaluate_tsinghua_pipeline(gumnet_model, imposter_pairs, desc=\"Imposter\")\n",
    "\n",
    "d_prime_base = calculate_d_prime(gen_base, imp_base)\n",
    "d_prime_aligned = calculate_d_prime(gen_aligned, imp_aligned)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"{'TSINGHUA DATASET: BIOMETRIC MATCHING PERFORMANCE':^70}\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Metric':<25} | {'Baseline':<12} | {'GumNet-AP-2D':<12} | {'Delta':<10}\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Genuine Mean (μ_gen)':<25} | {gen_base.mean():<12.2f} | {gen_aligned.mean():<12.2f} | {(gen_aligned.mean() - gen_base.mean()):+.2f}\")\n",
    "print(\"-\" * 70)\n",
    "d_prime_label = \"Decidability Index (d')\"\n",
    "print(f\"{d_prime_label:<25} | {d_prime_base:<12.4f} | {d_prime_aligned:<12.4f} | {(d_prime_aligned - d_prime_base):+.4f}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67e2ce3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Data...\n",
      "Constructed 320 Genuine Pairs.\n",
      "Constructed 102080 Imposter Pairs.\n",
      "Randomly sampling 2000 imposter pairs from 102080...\n",
      "\n",
      "Loading GumNet model...\n",
      "Successfully loaded weights from ./checkpoints/gumnetmp_2d_best_noise_level_0_8x8_200.pth\n",
      "\n",
      "Running Genuine Pairs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Genuine: 100%|██████████| 320/320 [01:39<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Imposter Pairs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Imposter: 100%|██████████| 2000/2000 [09:44<00:00,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "           TSINGHUA DATASET: BIOMETRIC MATCHING PERFORMANCE           \n",
      "======================================================================\n",
      "Metric                    | Baseline     | GumNet-AP-2D | Delta     \n",
      "----------------------------------------------------------------------\n",
      "Genuine Mean (μ_gen)      | 40.88        | 42.90        | +2.01\n",
      "----------------------------------------------------------------------\n",
      "Decidability Index (d')   | 1.4306       | 1.4227       | -0.0080\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "CHECKPOINT_PATH = './checkpoints/gumnetmp_2d_best_noise_level_0_8x8_200.pth'\n",
    "print(\"Initializing Data...\")\n",
    "genuine_pairs, imposter_pairs = construct_tsinghua_pairs(TSINGHUA_DATA_DIR)\n",
    "\n",
    "if len(imposter_pairs) > 2000:\n",
    "    print(f\"Randomly sampling 2000 imposter pairs from {len(imposter_pairs)}...\")\n",
    "    imposter_pairs = random.sample(imposter_pairs, 2000)\n",
    "\n",
    "print(\"\\nLoading GumNet model...\")\n",
    "gumnet_model = GumNetMP(in_channels=1, grid_size=GRID_SIZE).to(DEVICE)\n",
    "if os.path.exists(CHECKPOINT_PATH):\n",
    "    gumnet_model.load_state_dict(torch.load(CHECKPOINT_PATH, map_location=DEVICE))\n",
    "    print(f\"Successfully loaded weights from {CHECKPOINT_PATH}\")\n",
    "else:\n",
    "    print(f\"ERROR: Checkpoint {CHECKPOINT_PATH} not found!\")\n",
    "\n",
    "print(\"\\nRunning Genuine Pairs...\")\n",
    "gen_base, gen_aligned = evaluate_tsinghua_pipeline(gumnet_model, genuine_pairs, desc=\"Genuine\")\n",
    "\n",
    "print(\"\\nRunning Imposter Pairs...\")\n",
    "imp_base, imp_aligned = evaluate_tsinghua_pipeline(gumnet_model, imposter_pairs, desc=\"Imposter\")\n",
    "\n",
    "# --- Print CVPR-Ready Results ---\n",
    "d_prime_base = calculate_d_prime(gen_base, imp_base)\n",
    "d_prime_aligned = calculate_d_prime(gen_aligned, imp_aligned)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"{'TSINGHUA DATASET: BIOMETRIC MATCHING PERFORMANCE':^70}\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Metric':<25} | {'Baseline':<12} | {'GumNet-AP-2D':<12} | {'Delta':<10}\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Genuine Mean (μ_gen)':<25} | {gen_base.mean():<12.2f} | {gen_aligned.mean():<12.2f} | {(gen_aligned.mean() - gen_base.mean()):+.2f}\")\n",
    "print(\"-\" * 70)\n",
    "d_prime_label = \"Decidability Index (d')\"\n",
    "print(f\"{d_prime_label:<25} | {d_prime_base:<12.4f} | {d_prime_aligned:<12.4f} | {(d_prime_aligned - d_prime_base):+.4f}\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
